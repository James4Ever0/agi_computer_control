{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# a good reference:\n# https://blog.paperspace.com/generating-text-summaries-gpt-2/\n!pip3 install einops\n\nimport einops\nimport transformers\nimport torch\n\nMODEL_NAME = 'gpt2'\nmodel = transformers.GPT2LMHeadModel.from_pretrained(MODEL_NAME)\ntokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n\nlr = 0.0001\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef build_special_token(location:str, name:str):\n    return f\"<|{location}_{name}|>\"\n\ndef generate_special_token_pair(name:str):\n    begin_token = build_special_token('begin', name)\n    end_token = build_special_token('end', name)\n    return begin_token, end_token\n\ntext = \"8e7d4f\"\n# text = \"0100100010010\"\nenc = tokenizer([text], return_tensors='pt')\ninput_ids = enc['input_ids'] # into three pieces only.\nattention_mask = torch.ones(input_ids.shape, dtype=torch.int64)\ninput_ids.shape\n\nbegin_bytes, end_bytes = generate_special_token_pair('bytes')\n# how to step in and out?\ntokenizer(begin_bytes)['input_ids'], tokenizer(end_bytes)['input_ids']","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-18T12:47:30.818463Z","iopub.execute_input":"2023-12-18T12:47:30.818902Z","iopub.status.idle":"2023-12-18T12:47:46.708755Z","shell.execute_reply.started":"2023-12-18T12:47:30.818851Z","shell.execute_reply":"2023-12-18T12:47:46.707289Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (0.7.0)\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"([27, 91, 27471, 62, 33661, 91, 29], [27, 91, 437, 62, 33661, 91, 29])"},"metadata":{}}]},{"cell_type":"code","source":"# print(dir(tokenizer))\n# print(tokenizer.all_special_tokens)\n# help(tokenizer.add_tokens)\ntokenizer.add_tokens([begin_bytes, end_bytes]) # will not do this again.\n# tokenizer.add_special_tokens({\"begin_bytes\": begin_bytes, \"end_bytes\":end_bytes})","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:46.711535Z","iopub.execute_input":"2023-12-18T12:47:46.712026Z","iopub.status.idle":"2023-12-18T12:47:46.719994Z","shell.execute_reply.started":"2023-12-18T12:47:46.711976Z","shell.execute_reply":"2023-12-18T12:47:46.719079Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"# add new special token to tokenizer\nlen(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:46.721234Z","iopub.execute_input":"2023-12-18T12:47:46.722079Z","iopub.status.idle":"2023-12-18T12:47:46.742747Z","shell.execute_reply.started":"2023-12-18T12:47:46.722047Z","shell.execute_reply":"2023-12-18T12:47:46.741629Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"50259"},"metadata":{}}]},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:46.744485Z","iopub.execute_input":"2023-12-18T12:47:46.745204Z","iopub.status.idle":"2023-12-18T12:47:47.490816Z","shell.execute_reply.started":"2023-12-18T12:47:46.745171Z","shell.execute_reply":"2023-12-18T12:47:47.489607Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Embedding(50259, 768)"},"metadata":{}}]},{"cell_type":"code","source":"# dir(tokenizer)\n# tokenizer.vocab\n\n# binary_vocab = {i: format(i, '04b') for i in range(16)}\n# binary_map = {v: tokenizer.vocab[v] for _, v in binary_vocab.items()}\n\n# missing: 0011\n\nhex_vocab = {i: format(i, '0x') for i in range(16)}\nhex_map = {v: tokenizer.vocab[v] for _, v in hex_vocab.items()}\n# hex_map","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:47.494869Z","iopub.execute_input":"2023-12-18T12:47:47.495987Z","iopub.status.idle":"2023-12-18T12:47:47.944218Z","shell.execute_reply.started":"2023-12-18T12:47:47.495936Z","shell.execute_reply":"2023-12-18T12:47:47.942791Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"byte_vocab = {i: str(i) for i in range(256)}\nbyte_map = {v: tokenizer.vocab[v] for _, v in byte_vocab.items()}\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:47.946107Z","iopub.execute_input":"2023-12-18T12:47:47.946859Z","iopub.status.idle":"2023-12-18T12:47:54.994281Z","shell.execute_reply.started":"2023-12-18T12:47:47.946797Z","shell.execute_reply":"2023-12-18T12:47:54.993004Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"output.logits.shape # now: 50259\n# <|begin_bytes|>feffd3d7ea<|end_bytes|>\n# <|begin_hex|>feffd3d7ea<|end_hex|>\n# .............##########[#..........] <- in training we only mask some prob\n# .............####################### <- in inference/parsing there could be state rolling back","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:48:40.597113Z","iopub.execute_input":"2023-12-18T12:48:40.597544Z","iopub.status.idle":"2023-12-18T12:48:40.605249Z","shell.execute_reply.started":"2023-12-18T12:48:40.597513Z","shell.execute_reply":"2023-12-18T12:48:40.604217Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 6, 50259])"},"metadata":{}}]},{"cell_type":"code","source":"# training\noutput = model(input_ids = input_ids, attention_mask = attention_mask)\n# output.logits[:,:,:] = 0 # this will not affect loss\nmasked_logits = torch.zeros(output.logits.shape)\nfocused_ids = [10,20,30]\nmasked_logits[:,:,focused_ids] = output.logits[:,:,focused_ids] # this will\n\nzero_input_ids = torch.zeros(input_ids.shape, dtype=input_ids.dtype)\n# output.logits\nreshaped_original_logits = einops.rearrange(output.logits, \"b s c -> b c s\")\nreshaped_logits = einops.rearrange(masked_logits, \"b s c -> b c s\")\nloss = loss_fn(reshaped_original_logits, zero_input_ids)\n# loss = loss_fn(reshaped_logits, zero_input_ids)\nprint(loss.item()) # it would be the same as long as setting to zero.\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:55.003222Z","iopub.execute_input":"2023-12-18T12:47:55.003600Z","iopub.status.idle":"2023-12-18T12:47:55.118226Z","shell.execute_reply.started":"2023-12-18T12:47:55.003565Z","shell.execute_reply":"2023-12-18T12:47:55.116924Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"113.70537567138672\n","output_type":"stream"}]},{"cell_type":"code","source":"masked_logits[:,:,focused_ids]","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:55.120295Z","iopub.execute_input":"2023-12-18T12:47:55.120772Z","iopub.status.idle":"2023-12-18T12:47:55.132497Z","shell.execute_reply.started":"2023-12-18T12:47:55.120727Z","shell.execute_reply":"2023-12-18T12:47:55.131105Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"tensor([[[ -36.2464,  -35.9492,  -35.7844],\n         [-119.4347, -116.3841, -121.1023],\n         [-118.1599, -120.0545, -118.7981],\n         [-132.1329, -127.4328, -132.6541],\n         [-114.5634, -117.4611, -115.0835],\n         [-130.6806, -125.9233, -131.4073]]], grad_fn=<IndexBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"model.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:55.133770Z","iopub.execute_input":"2023-12-18T12:47:55.134164Z","iopub.status.idle":"2023-12-18T12:47:55.142173Z","shell.execute_reply.started":"2023-12-18T12:47:55.134131Z","shell.execute_reply":"2023-12-18T12:47:55.140541Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"loss.backward()\noptimizer.step()\nmodel.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:55.144993Z","iopub.execute_input":"2023-12-18T12:47:55.145944Z","iopub.status.idle":"2023-12-18T12:47:56.222776Z","shell.execute_reply.started":"2023-12-18T12:47:55.145888Z","shell.execute_reply":"2023-12-18T12:47:56.221535Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# inference","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:47:56.224433Z","iopub.execute_input":"2023-12-18T12:47:56.224873Z","iopub.status.idle":"2023-12-18T12:47:56.230426Z","shell.execute_reply.started":"2023-12-18T12:47:56.224810Z","shell.execute_reply":"2023-12-18T12:47:56.229222Z"},"trusted":true},"execution_count":45,"outputs":[]}]}